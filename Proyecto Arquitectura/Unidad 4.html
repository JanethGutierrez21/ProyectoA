<!DOCTYPE html>
<html lang="en">
<head>
    
    <title>Unidad 1 </title>
</head>
<body bgcolor= "#f677fd" text = "black">
    
    <header> 
        <p> <font class="tituloUnidad"></i> Arquitectura de Computadoras</font> </i> </p> 
    </header>

    <header class="unidades">
        <p> <font class="tituloUnidad"> <a href="Index.html">Unidad 1</a> &nbsp; &nbsp; <a href="Unidad 2.html">Unidad 2</a>  &nbsp; &nbsp; <a href="Unidad 3.html">Unidad 3</a>  &nbsp; &nbsp; <a href="Unidad 4.html">Unidad 4 </a>  &nbsp; &nbsp; <a href="Practicas.html"> Prácticas </a></font> </p>
    </header>

        <article>
            <font class="title"> <center> Unidad 4 </center></font>
            <p> <br> </p>
            <h2 id="4.1">4.1 Aspectos Básicos de la Computación Paralela</h2> <hr>
            <p class="text">Es una técnica de procesamiento de información que se basa en la utilización de múltiples procesadores para llevar a cabo una tarea en paralelo, en lugar de usar un solo procesador.</p>
            <p class="text">Permite mejorar significativamente la velocidad y eficiencia de los cálculos y análisis de datos en la computadora.</p>
            <h4> Ley de Amdahl y Ley de Gustafson </h4>
            <p class="text">Idealmente, la aceleración a partir de la paralelización es lineal, doblar el número de elementos de procesamiento debe reducir a la mitad el tiempo de ejecución y doblarlo por segunda vez debe nuevamente reducir el tiempo a la mitad. Sin embargo, muy pocos algoritmos paralelos logran una aceleración óptima. La mayoría tienen una aceleración casi lineal para un pequeño número de elementos de procesamiento, y pasa a ser constante para un gran número de elementos de procesamiento.</p>
            <p class="text">La aceleración potencial de un algoritmo en una plataforma de cómputo en paralelo está dada por la ley de Amdahl, formulada originalmente por Gene Amdahl en la década de 1960. Esta señala que una pequeña porción del programa que no pueda paralelizarse va a limitar la aceleración que se logra con la paralelización.</p>
            <p class="text">La ley de Gustafson es otra ley en computación que está en estrecha relación con la ley de Amdahl. Ambas leyes asumen que el tiempo de funcionamiento de la parte secuencial del programa es independiente del número de procesadores. La ley de Amdahl supone que todo el problema es de tamaño fijo, por lo que la cantidad total de trabajo que se hará en paralelo también es independiente del número de procesadores, mientras que la ley de Gustafson supone que la cantidad total de trabajo que se hará en paralelo varía linealmente con el número de procesadores.</p>
              <center><img src= "computacion paralela.jpg"></center> <p><br></p>
            
            <h2 id="4.2">4.2 Tipos de Computación Paralela</h2> <hr>
            <h4> Paralelismo a nivel de bit </h4>
            <p class="text">Desde el advenimiento de la integración a gran escala (VLSI) como tecnología de fabricación de chips de computadora en la década de 1970 hasta alrededor de 1986, la aceleración en la arquitectura de computadores se lograba en gran medida duplicando el tamaño de la palabra en la computadora, la cantidad de información que el procesador puede manejar por ciclo.</p>
            <p class="text">Históricamente, los microprocesadores de 4 bits fueron sustituidos por unos de 8 bits, luego de 16 bits y 32 bits, esta tendencia general llegó a su fin con la introducción de procesadores de 64 bits, lo que ha sido un estándar en la computación de propósito general durante la última década.</p>
            <h4> Paralelismo a nivel de instrucción </h4>
            <p class="text">Los procesadores modernos tienen ''pipeline'' de instrucciones de varias etapas. Cada etapa en el pipeline corresponde a una acción diferente que el procesador realiza en la instrucción correspondiente a la etapa; un procesador con un pipeline de N etapas puede tener hasta n instrucciones diferentes en diferentes etapas de finalización.</p>
            <h4> Paralelismo de datos </h4>
            <p class="text">El paralelismo de datos es el paralelismo inherente en programas con ciclos, que se centra en la distribución de los datos entre los diferentes nodos computacionales que deben tratarse en paralelo. Muchas de las aplicaciones científicas y de ingeniería muestran paralelismo de datos.</p>
            <p class="text">Una dependencia de terminación de ciclo es la dependencia de una iteración de un ciclo en la salida de una o más iteraciones anteriores. Las dependencias de terminación de ciclo evitan la paralelización de ciclos.</p>
            <h4> Paralelismo de tareas </h4>
            <p class="text">Es un paradigma de la programación concurrente que consiste en asignar distintas tareas a cada uno de los procesadores de un sistema de cómputo. En consecuencia, cada procesador efectuará su propia secuencia de operaciones. En su modo más general, el paralelismo de tareas se representa mediante un grafo de tareas, el cual es subdividido en subgrafos que son luego asignados a diferentes procesadores.</p><p><br></p>

            <h1 id="4.2.1">4.2.1 Clasificación</h1>
            <p class="text">Las computadoras paralelas se pueden clasificar de acuerdo con el nivel en el que el hardware soporta paralelismo. Esta clasificación es análoga a la distancia entre los nodos básicos de cómputo.</p>
            <p class="text"><b>Computación multinúcleo: </b>un procesador multinúcleo es un procesador que incluye múltiples unidades de ejecución (núcleos) en el mismo chip.</p>
            <p class="text"><b>Multiprocesamiento simétrico: </b>un multiprocesador simétrico (SMP) es un sistema computacional con múltiples procesadores idénticos que comparten memoria y se conectan a través de un bus.</p>
            <p class="text"><b>Computación en clúster: </b>un clúster es un grupo de ordenadores débilmente acoplados que trabajan en estrecha colaboración, de modo que en algunos aspectos pueden considerarse como un solo equipo.</p>
            <p class="text"><b>Procesamiento paralelo masivo: </b>tienden a ser más grandes que los clústeres, con «mucho más» de 100 procesadores.</p>
            <p class="text"><b>Computación distribuida: </b>es la forma más distribuida de la computación paralela. Se hace uso de ordenadores que se comunican a través de la Internet para trabajar en un problema dado.</p>
            <p class="text"><b>Circuitos integrados de aplicación específica: </b>debido a que un ASIC (por definición) es específico para una aplicación dada, puede ser completamente optimizado para esa aplicación.</p>
            <p class="text"><b>Procesadores vectoriales: </b>pueden ejecutar la misma instrucción en grandes conjuntos de datos.</p><p><br></p>

            <h1 id="4.2.2">4.2.2 Arquitectura de Computadoras Secuenciales</h1>
            <p class="text">Se basan en el método introducido por Jonh Von Neumann, la que consiste en:</p>
            <p class="text">-Una unidad central de procesamiento (CPU)</p>
            <p class="text">-Memoria principal para almacenar información</p>
            <p class="text">-Bus donde fluyan los datos</p>
            <p class="text">-Mecanismo de sincronización.</p><p><br></p>

            <h1 id="4.2.3">4.2.3 Organización de Direcciones de Memoria</h1>
            <p class="text"><b> Organización Logica:</b>los programas a menudo están organizados en módulos, algunos de los cuales pueden ser compartidos por diferentes programas. La gestión de memoria es responsable de manejar esta organización lógica que se contrapone al espacio de direcciones físicas lineales. Una forma de lograrlo es mediante la segmentación de memoria</p>
            <p class="text"><b> Organización física: </b>la memoria suele dividirse en un almacenamiento primario de alta velocidad y uno secundario de menor velocidad. La gestión de memoria del sistema operativo se ocupa de trasladar la información entre estos dos niveles de memoria.</p>
            <p class="text"><i> Hay dos tipos de organización de direcciones de memoria: :</i></p>
            <p class="text"><b> La organización de direcciones de memoria contiguas </b>es aquella en la que las celdas de memoria se organizan de forma consecutiva en la memoria. En esta la dirección de memoria de una celda se puede calcular sumando la dirección de la celda anterior  y el tamaño de la celda actual</p>
            <p class="text"><b> La organización de direcciones de memoria no contiguas </b>es aquella en la que las celdas de memoria se organizan en cualquier lugar de la memoria, sin ningún patrón predecible. En esta la dirección de memoria se asigna a cada celda de forma independiente </p>
             <p class="text">La organización de memoria contiguas es más eficiente que la organización de direcciones de memoria no contiguas, ya que permite un acceso más rápido a la memoria.</p><p><br></p>           

            <h2 id="4.3">4.3 Sistemas de Memoria Compartida</h2> <hr>
            <p class="text">Es aquel tipo de memoria que puede ser accedida por múltiples programas, para comunicarse entre ellos o para evitar copias redundantes. Es un modo eficaz de pasar datos entre aplicaciones. </p>
            <p class="text">Funciona permitiendo que múltiples procesos accedan a la misma región de memoria. Esto significa que cada proceso puede leer y escribir en la misma sección de memoria, lo que les permite compartir información y comunicarse entre sí de manera eficiente.</p>
            <p class="text">Un sistema de memoria compartida puede ser configurado para que varias particiones lógicas compartan una agrupación de memoria física</p>
            <h4> <i> Multiprocesadores </i> </h4> 
            <p class="text">Son sistemas dentro de una computadora que implementan el multiprocesamiento, utilizan más de un procesador para procesar paralelamente y esto mejora la velocidad de ejecución del sistema </p>
            <p class="text"><b>Multiprocesadores poco acoplados:</b> cada procesador tiene su propia memoria local, canales de IO y sistema operativo. Los procesadores intercambian datos a través de una red de alta velocidad a través de mensajes. Permiten sistemas de memoria distribuida la cual es altamente escalable.</p>
            <p class="text"><b>Multiprocesadores altamente acoplados:</b> es un multiprocesador con una memoria compartida y altamente acoplada a los procesadores. </p><p><br></p>
             <center><img src= "memoria.jpg"></center> <p><br></p>

            <h1 id="4.3.1">4.3.1 Redes de Interconexión Dinámicas ó Indirectas</h1>
            <p class="text">Las redes de interconexión dinámicas son sistemas de comunicación que permiten la transferencia de datos en tiempo real ente diferentes dispositivos y plataformas. Se caracterizan por su capacidad para adaptarse a diferentes entornos y situaciones, lo que les permite optimizar la comunicación y el intercambio de información en diferentes contextos y sectores. Son convenientes en los casos en que se desee una red de proposito general ya que son fácilmente reconfigurables, se caracterizan por su flexibilidad y escalabilidad, lo que les permite adaptarse a diferentes entornos y necesidades empresariales.</p>
            <p class="text">Ofrecen numerosos beneficios para las empresas, como la mejora de la eficiencia y la reducción de costos operativos.</p>
            <h4> <i> Medio Compartido: </i> </h4>
            <p class="text">Técnica utilizada para compartir recursos entre varios componentes de hardware, como procesadores y dispositivos de almacenamiento. Puede ofrecer ventajas en términos de simplicidad, flexibilidad y eficiencia en el uso de los  recursos, sin embargo, puede presentar algunas limitaciones como la necesidad de coordinar el acceso al medio compartido entre los diferentes componentes para evitar colisiones de datos y garantizar un rendimiento optimo.</p><p><br></p>
            <h4> <i> Conmutadas: </i> </h4>
            <p class="text">Una red de interconexión conmutada es un tipo de red que conecta dispositivos de forma que puedan comunicarse entre sí. La “conmutación” se refiere a la capacidad de la red para enrutar el tráfico entre los dispositivos conectados de manera eficiente. </p>
            <p class="text">Su arquitectura es la capa de transporte, la capa de control y la capa de la aplicación, cada una con sus funciones y protocolos de comunicación. </p>
            <p class="text">Ofrecen numerosas ventajas como la escalabilidad, la flexibilidad y la eficiencia energética. Tiene múltiples aplicaciones en diferentes sectores como la industria, la salud, el transporte y la seguridad.</p><p><br></p>

            <h2 id="4.4">4.4 Sistemas de Memoria Distribuida: Multiprocesadores</h2> <hr>
           <h4> <i> Multicomputadores </i> </h4>
            <p class="text"> Se pueden ver como un computador paralelo en el cual cada procesador tiene su propia memoria local. En estos la memoria se encuentra distribuida y no compartida como en los sistemas de multiprocesador. Se comunican a través del paso de mensajes, ya que estos solo tienen acceso directo a su memoria local y no a las memorias del resto de procesadores.</p>
            <h4> <i> Caracteristicas: </i> </h4>            
            <p class="text">-La memoria es privada</p>
            <p class="text">-Los nodos colaboran para resolver juntos un mismo problema </p>
            <p class="text">-En un multicomputador , cada nodo es una computadora clásica. </p>
            <p class="text">-La compartición de datos es explicita, ya que el acceso a datos comunes es por paso de mensajes.</p><p><br></p>

            <h1 id="4.4.1">4.4.1 Redes de Interconexión Estáticas</h1>
            <p class="text">Los multicomputadores utilizan redes estáticas con enlaces directos entre nodos. Cuando un nodo recibe un mensaje lo procesa si viene dirigido a dicho nodo. </p>
            <h4> <i>Tipologías</i> </h4>
            <p class="text"><b>Topología en estrella:</b> todos los dispositivos están conectados a un centro común, como un concentrador o un switch. Los dispositivos no se conectan entre sí. </p>
            <p class="text"><b>Topología en bus:</b> todos los dispositivos se conectan a un solo cable de comunicaciones, se comunican entre si enviando y recibiendo señales en este cable. </p>
            <p class="text"><b>Topología en anillo:</b> los dispositivos se conectan en forma de anillo cerrado. Cada dispositivo se conecta al dispositivo adyacente y la señal se transmite a través del anillo hasta que llega al destino. </p>
            <p class="text"><b>Topología en malla:</b> cada dispositivo se conecta a todos los demás dispositivos en la red. Esto proporciona redundancia y resiliencia en la red  </p>
             <center><img src= "conexiones estaticas.jpg"></center> <p><br></p>

            <h2 id="4.5">4.5 Casos de Estudio </h2> <hr>
            <p class="text">El procesamiento distribuido se ha convertido en un área de gran importancia e interés dentro de la ciencia de la computación, produciendo distintas transformaciones en la investigación y el desarrollo.</p>
             <h4> <i> Nivia </i> </h4>
            <p class="text">Es una empresa que diseña y fabrica tarjetas gráficas, procesadores y sistemas de computación y sistemas de computación de alto rendimiento. Su tecnología CUD permite la computación paralela en sus tarjetas gráficas, lo que las hace ideales para aplicaciones como la inteligencia artificial, la simulación y el procesamiento de imágenes.</p>
            <h4> <i> Google Cloud Plataform </i> </h4>
            <p class="text">Es un servicio de computación en la nube que utiliza la computación paralela para procesar grandes cantidades de datos, ha desarrollado su propio procesador de inteligencia artificial TPU(Tensor Proccesing Unit) que la utiliza para acelerar el entrenamiento de redes neuronales.</p>
            <h4> <i> IBM </i> </h4>
            <p class="text">Ha desarrollado una variedad de productos y servicios de computación paralela, incluyendo el sistema de computación en paralelo IBM Blue Gene, que ha sido utilizado en aplicaciones científicas y de ingeniería</p><p><br></p>
    
        </article>
    </section>

</body>
</html>